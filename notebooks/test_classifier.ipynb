{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pillow\n",
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import io\n",
    "import boto3\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Constants\n",
    "BUCKET_NAME = \"pnuemonia-chest-xrays-ids721\"\n",
    "MODEL_PATH = \"models/pnuemonia_model.pt\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train=True, test=True, val=True):\n",
    "    # Create the client\n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "    # Generate the prefixes for each image set\n",
    "    train_prefix = \"chest_xrays/train\"\n",
    "    test_prefix = \"chest_xrays/test\"\n",
    "    val_prefix = \"chest_xrays/val\"\n",
    "    \n",
    "    # Load the data\n",
    "    if train:\n",
    "        print(\"Loading the training data...\")\n",
    "        normal_train = get_s3_objects(s3, train_prefix, \"NORMAL\")\n",
    "        pnue_train = get_s3_objects(s3, train_prefix, \"PNEUMONIA\")\n",
    "        \n",
    "        Xtrain, ytrain = combine_data(normal_train, pnue_train)\n",
    "    \n",
    "    if test:\n",
    "        print(\"Loading the testing data...\")\n",
    "        normal_test = get_s3_objects(s3, test_prefix, \"NORMAL\")\n",
    "        pnue_test = get_s3_objects(s3, test_prefix, \"PNEUMONIA\")\n",
    "        \n",
    "        Xtest, ytest = combine_data(normal_test, pnue_test)\n",
    "    \n",
    "    if val:\n",
    "        print(\"Loading the validation data...\")\n",
    "        normal_val = get_s3_objects(s3, val_prefix, \"NORMAL\")\n",
    "        pnue_val = get_s3_objects(s3, val_prefix, \"PNEUMONIA\")\n",
    "        \n",
    "        Xval, yval = combine_data(normal_val, pnue_val)\n",
    "    \n",
    "    if train and test and val:\n",
    "        return Xtrain, ytrain, Xtest, ytest, Xval, yval\n",
    "    if train and test:\n",
    "        return Xtrain, ytrain, Xtest, ytest\n",
    "    if train and val:\n",
    "        return Xtrain, ytrain, Xval, yval\n",
    "    if test and val:\n",
    "        return Xtest, ytest, Xval, yval\n",
    "    if train:\n",
    "        return Xtrain, ytrain\n",
    "    if test:\n",
    "        return Xtest, ytest\n",
    "    if val:\n",
    "        return Xval, yval\n",
    "    \n",
    "    return None\n",
    "\n",
    "def get_s3_objects(s3_client, prefix, class_name):\n",
    "    # Get the list of objects in the bucket\n",
    "    files = s3_client.list_objects(Bucket=BUCKET_NAME, Prefix=f\"{prefix}/{class_name}\")[\"Contents\"]\n",
    "    \n",
    "    # Get the filenames\n",
    "    filenames = [file[\"Key\"] for file in files]\n",
    "    \n",
    "    # Loop thruogh the filenames\n",
    "    images = []\n",
    "    for file in filenames:\n",
    "        try: \n",
    "            # Get the object\n",
    "            file_obj = io.BytesIO()\n",
    "            s3_client.download_fileobj(Bucket=BUCKET_NAME, Key=file, Fileobj=file_obj)\n",
    "            # Load the image\n",
    "            img = Image.frombytes(mode=\"L\", size=(112, 112), data=file_obj.getvalue())\n",
    "            img = np.array(img.resize((224, 224)))\n",
    "            # Mimic RGB to use pretrained model\n",
    "            rgb_img = np.repeat(img[:, :, np.newaxis], 3, -1)\n",
    "            images.append(rgb_img)\n",
    "        except:\n",
    "            continue # If there is an error, skip the file\n",
    "    \n",
    "    return images\n",
    "    \n",
    "def combine_data(normal, pnue):\n",
    "    # Generate the labels\n",
    "    labels = [0] * len(normal) + [1] * len(pnue)\n",
    "\n",
    "    # Combine the data\n",
    "    images = normal + pnue\n",
    "\n",
    "    # Shuffle the data\n",
    "    random.seed(42)\n",
    "    random.shuffle(images)\n",
    "    random.shuffle(labels)\n",
    "    \n",
    "    # Return the results\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to setup modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(xval, yval, batch_size=8):\n",
    "    # Create the datasets\n",
    "    val_data = TensorDataset(torch.tensor(np.array(xval)).float() , torch.tensor(np.array(yval)))\n",
    "    \n",
    "    # Create the dataloaders\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Return the dataloaders\n",
    "    return val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    # Get resnet50 model\n",
    "    model = torchvision.models.resnet50(pretrained=True)\n",
    "    \n",
    "    # Freeze the parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    # Define the classifier\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 2)\n",
    "    \n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for testing and loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, data_loader):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    # For each batch\n",
    "    for inputs, labels in data_loader:\n",
    "        inputs = inputs.reshape(-1, 3, 224, 224)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Feed inputs through model to get raw scores\n",
    "        logits = model.forward(inputs)\n",
    "        # Convert raw scores to probabilities (not necessary since we just care about discrete probs in this case)\n",
    "        probs = F.softmax(logits,dim=1)\n",
    "        # Get discrete predictions using argmax\n",
    "        preds = np.argmax(probs.cpu().detach().numpy(),axis=1)\n",
    "        # Add predictions and actuals to lists\n",
    "        y_pred.extend(preds)\n",
    "        y_true.extend(labels.cpu())\n",
    "    \n",
    "    # Calculate the accuracy\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    accuracy = np.sum(y_pred == y_true)/y_true.shape[0]\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    # Download the model from S3\n",
    "    s3 = boto3.client('s3')\n",
    "    s3.download_file(BUCKET_NAME, MODEL_PATH, MODEL_PATH)\n",
    "    \n",
    "    # Load the model\n",
    "    model = define_model()\n",
    "    model.load_state_dict(torch.load(MODEL_PATH))\n",
    "    \n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "Xtest, ytest = load_data(train=False, test=True, val=False)\n",
    "\n",
    "# Create the dataloader\n",
    "test_data = create_dataloaders(Xtest, ytest)\n",
    "\n",
    "# Load the model\n",
    "model = load_model()\n",
    "\n",
    "# Get the accuracy\n",
    "accuracy = test_model(model, test_data)\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
