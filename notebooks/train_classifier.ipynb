{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pillow\n",
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import io\n",
    "import boto3\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Constants\n",
    "BUCKET_NAME = \"pnuemonia-chest-xrays-ids721\"\n",
    "MODEL_PATH = \"models/pnuemonia_model.pt\"\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train=True, test=True, val=True):\n",
    "    # Create the client\n",
    "    s3 = boto3.client('s3')\n",
    "\n",
    "    # Generate the prefixes for each image set\n",
    "    train_prefix = \"chest_xrays/train\"\n",
    "    test_prefix = \"chest_xrays/test\"\n",
    "    val_prefix = \"chest_xrays/val\"\n",
    "    \n",
    "    # Load the data\n",
    "    if train:\n",
    "        print(\"Loading the training data...\")\n",
    "        normal_train = get_s3_objects(s3, train_prefix, \"NORMAL\")\n",
    "        pnue_train = get_s3_objects(s3, train_prefix, \"PNEUMONIA\")\n",
    "        \n",
    "        Xtrain, ytrain = combine_data(normal_train, pnue_train)\n",
    "    \n",
    "    if test:\n",
    "        print(\"Loading the testing data...\")\n",
    "        normal_test = get_s3_objects(s3, test_prefix, \"NORMAL\")\n",
    "        pnue_test = get_s3_objects(s3, test_prefix, \"PNEUMONIA\")\n",
    "        \n",
    "        Xtest, ytest = combine_data(normal_test, pnue_test)\n",
    "    \n",
    "    if val:\n",
    "        print(\"Loading the validation data...\")\n",
    "        normal_val = get_s3_objects(s3, val_prefix, \"NORMAL\")\n",
    "        pnue_val = get_s3_objects(s3, val_prefix, \"PNEUMONIA\")\n",
    "        \n",
    "        Xval, yval = combine_data(normal_val, pnue_val)\n",
    "    \n",
    "    if train and test and val:\n",
    "        return Xtrain, ytrain, Xtest, ytest, Xval, yval\n",
    "    if train and test:\n",
    "        return Xtrain, ytrain, Xtest, ytest\n",
    "    if train and val:\n",
    "        return Xtrain, ytrain, Xval, yval\n",
    "    if test and val:\n",
    "        return Xtest, ytest, Xval, yval\n",
    "    if train:\n",
    "        return Xtrain, ytrain\n",
    "    if test:\n",
    "        return Xtest, ytest\n",
    "    if val:\n",
    "        return Xval, yval\n",
    "    \n",
    "    return None\n",
    "    \n",
    "def get_s3_objects(s3_client, prefix, class_name):\n",
    "    # Get the list of objects in the bucket\n",
    "    files = s3_client.list_objects(Bucket=BUCKET_NAME, Prefix=f\"{prefix}/{class_name}\")[\"Contents\"]\n",
    "    \n",
    "    # Get the filenames\n",
    "    filenames = [file[\"Key\"] for file in files]\n",
    "    \n",
    "    # Loop thruogh the filenames\n",
    "    images = []\n",
    "    for file in filenames:\n",
    "        try: \n",
    "            # Get the object\n",
    "            file_obj = io.BytesIO()\n",
    "            s3_client.download_fileobj(Bucket=BUCKET_NAME, Key=file, Fileobj=file_obj)\n",
    "            # Load the image\n",
    "            img = Image.frombytes(mode=\"L\", size=(112, 112), data=file_obj.getvalue())\n",
    "            img = np.array(img.resize((224, 224)))\n",
    "            # Mimic RGB to use pretrained model\n",
    "            rgb_img = np.repeat(img[:, :, np.newaxis], 3, -1)\n",
    "            images.append(rgb_img)\n",
    "        except:\n",
    "            continue # If there is an error, skip the file\n",
    "    \n",
    "    return images\n",
    "    \n",
    "def combine_data(normal, pnue):\n",
    "    # Generate the labels\n",
    "    labels = [0] * len(normal) + [1] * len(pnue)\n",
    "\n",
    "    # Combine the data\n",
    "    images = normal + pnue\n",
    "\n",
    "    # Shuffle the data\n",
    "    random.seed(42)\n",
    "    random.shuffle(images)\n",
    "    random.shuffle(labels)\n",
    "    \n",
    "    # Return the results\n",
    "    return images, labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to setup modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloaders(xval, yval, batch_size=8):\n",
    "    # Create the datasets\n",
    "    val_data = TensorDataset(torch.tensor(np.array(xval)).float() , torch.tensor(np.array(yval)))\n",
    "    \n",
    "    # Create the dataloaders\n",
    "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    # Return the dataloaders\n",
    "    return val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model():\n",
    "    # Get resnet50 model\n",
    "    model = torchvision.models.resnet50(pretrained=True)\n",
    "    \n",
    "    # Freeze the parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    # Define the classifier\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, 2)\n",
    "    \n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for training and saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, data_loader, num_epochs=1):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1} of {num_epochs}\")\n",
    "\n",
    "        # Set model to training mode\n",
    "        model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Get the input images and labels, and send to GPU if available\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = inputs.reshape(-1, 3, 224, 224)\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Zero the weight gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass to get outputs and calculate loss\n",
    "            # Track gradient only for training data\n",
    "            with torch.set_grad_enabled(True):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels.long())\n",
    "\n",
    "                # Backpropagation to get the gradients with respect to each weight\n",
    "                loss.backward()\n",
    "                # Update the weights\n",
    "                optimizer.step()\n",
    "\n",
    "            # Convert loss into a scalar and add it to running_loss\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            # Track number of correct predictions\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "    \n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, data_loader):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    # For each batch\n",
    "    for inputs, labels in data_loader:\n",
    "        inputs = inputs.reshape(-1, 3, 224, 224)\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Feed inputs through model to get raw scores\n",
    "        logits = model.forward(inputs)\n",
    "        # Convert raw scores to probabilities (not necessary since we just care about discrete probs in this case)\n",
    "        probs = F.softmax(logits,dim=1)\n",
    "        # Get discrete predictions using argmax\n",
    "        preds = np.argmax(probs.cpu().detach().numpy(),axis=1)\n",
    "        # Add predictions and actuals to lists\n",
    "        y_pred.extend(preds)\n",
    "        y_true.extend(labels.cpu())\n",
    "    \n",
    "    # Calculate the accuracy\n",
    "    y_pred = np.array(y_pred)\n",
    "    y_true = np.array(y_true)\n",
    "    accuracy = np.sum(y_pred == y_true)/y_true.shape[0]\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "    # Save the model\n",
    "    torch.save(model.state_dict(), MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the training data...\n",
      "Loading the testing data...\n",
      "Loading the validation data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bryce\\anaconda3\\envs\\IDS721\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\bryce\\anaconda3\\envs\\IDS721\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 10\n",
      "Epoch 2 of 10\n",
      "Epoch 3 of 10\n",
      "Epoch 4 of 10\n",
      "Epoch 5 of 10\n",
      "Epoch 6 of 10\n",
      "Epoch 7 of 10\n",
      "Epoch 8 of 10\n",
      "Epoch 9 of 10\n",
      "Epoch 10 of 10\n",
      "Training Accuracy: 0.6421421421421422\n",
      "Validation Accuracy: 0.5\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory models does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mValidation Accuracy: \u001b[39m\u001b[39m{\u001b[39;00mval_acc\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[39m# Save the model\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m save_model(model)\n",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave_model\u001b[39m(model):\n\u001b[0;32m      2\u001b[0m     \u001b[39m# Save the model\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     torch\u001b[39m.\u001b[39;49msave(model\u001b[39m.\u001b[39;49mstate_dict(), MODEL_PATH)\n\u001b[0;32m      5\u001b[0m     \u001b[39m# Save the model to S3\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     s3 \u001b[39m=\u001b[39m boto3\u001b[39m.\u001b[39mclient(\u001b[39m'\u001b[39m\u001b[39ms3\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\bryce\\anaconda3\\envs\\IDS721\\lib\\site-packages\\torch\\serialization.py:440\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    437\u001b[0m _check_save_filelike(f)\n\u001b[0;32m    439\u001b[0m \u001b[39mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m--> 440\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    441\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[0;32m    442\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bryce\\anaconda3\\envs\\IDS721\\lib\\site-packages\\torch\\serialization.py:315\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[1;34m(name_or_buffer)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    314\u001b[0m     container \u001b[39m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[1;32m--> 315\u001b[0m \u001b[39mreturn\u001b[39;00m container(name_or_buffer)\n",
      "File \u001b[1;32mc:\\Users\\bryce\\anaconda3\\envs\\IDS721\\lib\\site-packages\\torch\\serialization.py:288\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 288\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49mPyTorchFileWriter(\u001b[39mstr\u001b[39;49m(name)))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Parent directory models does not exist."
     ]
    }
   ],
   "source": [
    "# Get the data\n",
    "Xtrain, ytrain, Xval, yval = load_data(train=True, test=False, val=True)\n",
    "\n",
    "# Convert the data to tensors\n",
    "train_data = create_dataloaders(Xtrain, ytrain)\n",
    "val_data = create_dataloaders(Xval, yval)\n",
    "\n",
    "# Setup the mdoel\n",
    "model = define_model()\n",
    "critereon = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "model = train_model(model, critereon, optimizer, train_data, num_epochs=NUM_EPOCHS)\n",
    "\n",
    "# Get training and validation accuracy\n",
    "train_acc = test_model(model, train_data)\n",
    "val_acc = test_model(model, val_data)\n",
    "\n",
    "print(f\"Training Accuracy: {train_acc}\")\n",
    "print(f\"Validation Accuracy: {val_acc}\")\n",
    "\n",
    "# Save the model\n",
    "save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IDS721",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
